# Построчное чтение больших файлов

Используя `bufio`

Ну в принцие мохно и самому такое написать на любом `io.Reader`

Но в `bufio` есть готовый `func (b *Reader) ReadLine() (line []byte, isPrefix bool, err error)`,
который если зафиксировать размер буффера при помощи `func NewReaderSize(rd io.Reader, size int) *Reader`
будет вторым возвращаемым значением маркировать что строка превысила буфер.

Соотвественно мы спокойно игнорируем такю строку и смотрим следующую - она либо также превысит либо "закроет"
длинную строку - или значит еще раз скипнем или скипнем, но запомним, что длинная строка завершена.

Понятно размер буфера сразу можно выставить на свой лимит и не морочить себе мозг.

Собственно так [этот скрипт](../cmd/scanlarrgefile/scanlargefile.go) и написал.

Также приложил [генератор файла с длинными строками](../cmd/scanlarrgefile/generate_large_file_test.go)

> Заодно есть особенность - если строка РОВНО под размер буфера - она все равно isPrefix - то есть 
> буфер должен быть рассчитан и под `\n` значит размер буфера для нашей задачи нужен не 5mb, а 5mb + 1b

Скрипт всегда меряет длину строк и говорит будет ли он ее обрабатывать или нет, вывод такой:

```
Line #1 - PROCESSED - size - 10 bytes
Line #2 - PROCESSED - size - 20 bytes
Line #3 - PROCESSED - size - 1024 bytes
Line #4 - PROCESSED - size - 5242880 bytes
Line #5 - PROCESSED - size - 5242879 bytes
Line #6 - SKIPPED - too long - 6291456 bytes!
Line #7 - PROCESSED - size - 1000 bytes
```